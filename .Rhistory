# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
nortest::lillie.test(res.est) # Prueba de Lilliefors
# Para muestras pequeñas:
shapiro.test(res.est)         # Prueba de Shapiro-Wilks
moments::agostino.test(res.est)         # Prueba de D'Agostiino
# Para confirmar la influencia de las colas
nortest::ad.test(res.est)     # Prueba de Anderson-Darling
# Test no paramétrico
nortest::cvm.test(res.est)    # Prueba de Cramer Von-Mises
normtest::skewness.norm.test(res.est)   # Basada en asimetría
normtest::kurtosis.norm.test(res.est)   # Basada en kurtosis
normtest::jb.norm.test(res.est)         # prueba de Jarque-Bera (comprueba
# la asimetría y kurtosis a la vez)
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
nortest::lillie.test(res.est) # Prueba de Lilliefors
# Para muestras pequeñas:
shapiro.test(res.est)         # Prueba de Shapiro-Wilks
moments::agostino.test(res.est)         # Prueba de D'Agostiino
# Para confirmar la influencia de las colas
nortest::ad.test(res.est)     # Prueba de Anderson-Darling
# Test no paramétrico
nortest::cvm.test(res.est)    # Prueba de Cramer Von-Mises
normtest::skewness.norm.test(res.est)   # Basada en asimetría
normtest::kurtosis.norm.test(res.est)   # Basada en kurtosis
normtest::jb.norm.test(res.est)         # prueba de Jarque-Bera (comprueba
# la asimetría y kurtosis a la vez)
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
library(MASS)
library(car)
library(lmtest)
library(tseries)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
nortest::lillie.test(res.est) # Prueba de Lilliefors
# Para muestras pequeñas:
shapiro.test(res.est)         # Prueba de Shapiro-Wilks
moments::agostino.test(res.est)         # Prueba de D'Agostiino
# Para confirmar la influencia de las colas
nortest::ad.test(res.est)     # Prueba de Anderson-Darling
# Test no paramétrico
nortest::cvm.test(res.est)    # Prueba de Cramer Von-Mises
normtest::skewness.norm.test(res.est)   # Basada en asimetría
normtest::kurtosis.norm.test(res.est)   # Basada en kurtosis
normtest::jb.norm.test(res.est)         # prueba de Jarque-Bera (comprueba
# la asimetría y kurtosis a la vez)
Box.test(res.est, lag = 5, type = "Ljung-Box")	   	 # Prueba de Ljung-Box
acf(res.est, lag.max = 10, type = "correlation")$acf # Autocorrelaciones
tseries::runs.test(as.factor(sign(res.est)))	       # Prueba de rachas
influencia <- influence(ajuste)
# Leverages (diagonales de la "matriz sombrero")
lev <- influencia$hat
lev
dfajuste <- dffits(ajuste)
dfajuste
# DFBETAS
dfbeta <- influencia$coefficients
dfbeta
dfbetas(ajuste)
# Chequeamos sí:
sum(abs(dfajuste) > 2*sqrt(1/length(var.explicativa)))
# Empleando vcovCH() de la librería sandwich se obtiene un
# estimador más robusto de las desviaciones estándar de los
# coeficientes de un ajuste lineal
library(sandwich)
# solución estándar con
( vcov_estandar <- vcovHC(ajuste, type = "const") )
# solución más robusta ante heteroscedasticidad
( vcov_robusto <- vcovHC(ajuste, type = "HC1") )
# ahora las desviaciones estándar de los coeficientes estimados:
( robust_se <- sqrt(diag(vcov_robusto)) )
# Si además se desea el test de regresión empleando
# el F-test usar:
library(car)
lht(ajuste, hypothesis.matrix = "formación = 1",white.adjust = "hc1")
library(caret)
BoxCoxTrans(var.endogena)
library(caret)
x <- BoxCoxTrans(var.endogena)
predict(x, var.endogena)
var.endogena.transformada <- caret::BoxCoxTrans(var.endogena)
ajuste.transformado <- lm(var.endogena.transformada~var.explicativa)
# BoxCoxTrans devuelve el lambda, por lo que tenemos que aplicarlo a
# nuestra variable
var.endogena.transformada <- predict(lambda, var.endogena)
lambda <- caret::BoxCoxTrans(var.endogena)
# BoxCoxTrans devuelve el lambda, por lo que tenemos que aplicarlo a
# nuestra variable
var.endogena.transformada <- predict(lambda, var.endogena)
ajuste.transformado <- lm(var.endogena.transformada~var.explicativa)
influence
help("predict")
quantile(var.explicativa)
quantile(var.explicativa)[2:4]
valores.predecir <- c(1, 2, 3)
new.data <- data.frame(var.explicativa = valores.predecir)
new.data
head(var.explicativa)
IC.90 <- predict(ajuste, se.fit = TRUE, newdata = new.data,
interval = "confidence", level = 0.90)
IC.90
