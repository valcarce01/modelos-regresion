install.packages("rmdformats")
install.packages("pretty_doc")
install.packages("prettydoc")
prettydoc::html_pretty()
help(prettydoc::html_pretty)
help("prettydoc::html_pretty")
help(html_pretty)
iris
d <- 3
d <- 3
head(iris)
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
ajuste <- lm(var.endogena, var.explicativa)
datos <- data.frame(cbind(var.endogena, var.explicativa))
ajuste <- lm(var.endogena~var.explicativa, data = datos)
datos <- data.frame(cbind(var.endogena, var.explicativa))
ajuste <- lm(var.endogena~var.explicativa, data = datos)
ajuste
summary(ajuste)
res <- summary(ajuste)
attributes(res)
res$fstatistic
res$coefficients
# Contraste de regresión (H_0: beta_0 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
r <- cor(var.endogena, var.explicativa)
r
resumen
r
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
anova(ajuste)
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
contraste.regresion
leverage <- hatvalues(ajuste)
leverage
n.equivalente.datos <- 1/leverage
n.equivalente.datos
# AIC: Criterio de información de Akaike
# BIC: Criterio de Información Bayesiano
# Se introducirán con detalle en RLM. De momento nos quedamos con la
# idea de que cuánto menor su valor, mejor es el ajuste. En este caso:
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
library(DAAG)
# Validación cruzada
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit=TRUE, main="")
# Validación cruzada
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
# De cada uno de los "m" ajustes se calculan:
# "Sum of squares", o sea la suma de cuadrados de los residuos (SSR)
# "Mean square", o sea la suma de cuadrados promediada (MSSR)
# y "ms", el promedio de los "m" valores MSSR (en este caso ms=19)
# Esto último se puede obtener directamente con:
( MSSRcv  <- attr(cvRes, 'ms')  )
MSSR
MSSR <- SSR/gl.residuos           # media de SSR
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
# De cada uno de los "m" ajustes se calculan:
# "Sum of squares", o sea la suma de cuadrados de los residuos (SSR)
# "Mean square", o sea la suma de cuadrados promediada (MSSR)
# y "ms", el promedio de los "m" valores MSSR (en este caso ms=19)
# Esto último se puede obtener directamente con:
( MSSRcv  <- attr(cvRes, 'ms')  )
MSSR
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
# Validación cruzada
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
Los símbolos pequeños son las predicciones por validación cruzada
mientras que los símbolos grandes corresponden a las observaciones
reales.
library(stats)
stats::AIC()
stats::AIC(ajuste)
# Validación cruzada
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, #plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
BIC
help(BIC)
help("cor.test")
cor.test
help(cor)
data("iris")
var.endogena <- iris[,1]
var.explicativa <- iris[,2]
datos <- data.frame(cbind(var.endogena, var.explicativa))
library(DAAG)
library(stats)
ajuste <- lm(var.endogena~var.explicativa, data = datos)
coeficientes <- ajuste$coefficients
valores.ajustados <- ajuste$fitted.values
residuos <- ajuste$residuals
gl.residuos <- ajuste$df.residual # grados de libertad de los residuos
gl.modelo <- ajuste$rank          # grados de libertad del modelo
SSR <- sum(residuos^2)            # suma de residuos al cuadrado
MSSR <- SSR/gl.residuos           # media de SSR
leverage <- hatvalues(ajuste)
n.equivalente.datos <- 1/leverage
intervalo.parametros <- confint(ajuste, level = 0.95)
intervalo.varianza <- gl.residuos * MSSR / qchisq(p=0.10,df=gl.residuos)
# Contraste de regresión (H_0: beta_1 = 0):
resumen <- summary(ajuste)
contraste <- resumen$coefficients
# en la última columna tenemos el contraste de regrsión y el contraste de
# beta_0 = 0
# Podemos acceder al resultado del mismo contraste mediante anova:
contraste.regresion <- anova(ajuste)
# Coeficiente de correlación lineal de Pearson estimado:
r <- cor(var.endogena, var.explicativa)
# ¿Es significativamente diferente de cero? H0:rho=0 vs H1:rho!=0
cor.test(var.endogena, var.explicativa, method = "pearson")
# Coeficiente de determinación
R2 <- resumen$r.squared
R2.ajustado <- resumen$adj.r.squared
# AIC, Criterio de Información de Akaike
AIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# BIC, Criterio de Información Bayesiano (lo mismo, pero teniendo en cuenta
# el número de datos que tenemos)
BIC(ajuste)    # cuanto más pequeño, mejor (más ajustado)
# Validación cruzada
# hace un plot además con los 'distintos' modelos creados
cvRes <- DAAG::CVlm(data=datos, form.lm=var.endogena~var.explicativa,
m=5, dots=FALSE, seed=29, plotit="Observed",
legend.pos="topleft",
printit = FALSE, main="")
plot(ajuste)
plot(ajuste, which = 5)
plot(ajuste, which = 4)
plot(ajuste, which = 1)
plot(ajuste, which = 2)
plot(ajuste, which = 3)
plot(ajuste, which = 4)
plot(ajuste, which = 5)
as.factor(var.explicativa)
aj.aux <- lm(var.endogena~ as.factor(var.explicativa))
aj.aux
anova(ajuste, ajuste.aux)
anova(ajuste, aj.aux)
# La hipótesis alternativa la podemos expresar como una regresión de variables
# cualitativas:
var.explicativa.factor <- as.factor(var.explicativa)
ajuste.factor <- lm(var.endogena~var.explicativa, data = datos)
anova(ajuste, ajuste.factor)
ajuste.factor <- lm(var.endogena~var.explicativa.factor, data = datos)
anova(ajuste, ajuste.factor)
# Ilustración gráfica:
medias <- tapply(var.endogena, var.explicativa, mean)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
x11()
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
x11()
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
plot(var.explicativa, var.endogena, xlab="endógena",ylab="explicativa",
pch = 21, bg = "green", cex.lab=1.5, cex=0.9, cex.main=1.5)
# Ajuste bajo H_0
abline(ajuste, col="magenta", lwd=2)
# Ajuste bajo H_1
points(levels(var.explicativa.factor),medias,pch="-",cex=3,col="blue")
legend("topleft",c(expression(H[0]),expression(H[1])),
col=c("magenta","blue"),lty=c(1,1), cex=1.5)
kurtosis
skewness
shapiro.test()
library(MASS)
res.est <- MASS::stdres(ajuste)    # estudentizados internamente (o "estandarizados")
boxplot(var.endogena~var.explicativa)
# H0: sigma^2=cte  vs H1: sigma^2!=cte
# Test de Breusch-Pagan:
# H0: E(epsilon^2|X) = alpha0
# H1: E(epsilon^2|X) = alpha0 + alpha1X
# Sims like a contraste de regrsión con x_i y residuos alcuadrado
ncvTest(ajuste)  # equivale a bptest(ajuste,studentize = FALSE)
library(car)
car::ncvTest(ajuste)
library(lmtest)
lmtest::bptest(ajuste)
# Test de Breusch-Pagan:
# H0: E(epsilon^2|X) = alpha0
# H1: E(epsilon^2|X) = alpha0 + alpha1X
car::ncvTest(ajuste)
# ALEATORIEDAD
# sOLO TIENE sentido si tenemos almacenado en como se han recogido los datos
# (el orden temporal), sino no tiene sentido
Box.test(res.est, lag = 5, type = "Ljung-Box")	   	 # Prueba de Ljung-Box
help("Box.test")
library(tseries)
tseries::runs.test(as.factor(sign(res.est)))	                 # Prueba de rachas
